{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functions import preprocess, activations, losses"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "df = pd.read_csv('datasets/Train.csv')\n",
    "df = df.dropna(axis=1).drop(['ID','country','population'],axis=1)\n",
    "df2 = preprocess.min_max(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "features, target = df2.loc[:,'Q1':'Q25'], df2['target']\n",
    "\n",
    "X, Y = features.values.T, target.values\n",
    "x_train, y_train, x_test, y_test = preprocess.split(X, Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-layered Model\n",
    "<img src='images/net.png' width='500px'>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "def initiate_model(X, Y, learning_rate=0.001, hidden_layers=[10,10]):\n",
    "    \n",
    "    n_features = X.shape[0]\n",
    "    layers = [n_features, *hidden_layers, 1]\n",
    "    n_layers = len(layers)\n",
    "    \n",
    "    model = {\n",
    "        'learning_rate':learning_rate, \n",
    "        'layers':layers, \n",
    "        'Y':Y, \n",
    "        'loss':0,\n",
    "         'W':{}, 'B':{}, 'Z':{}, 'A':{0:X},\n",
    "        'dW':{},'dB':{},'dZ':{},'dA':{},\n",
    "        }\n",
    "\n",
    "    for layer in range(1, n_layers):\n",
    "        \n",
    "        model['W'][layer] = np.random.randn(layers[layer], layers[layer-1]) / np.sqrt(layers[layer-1])\n",
    "        model['B'][layer] = np.zeros((layers[layer], 1))\n",
    "                       \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "def forward_1_layer(W, A_min, B, act=activations.sigmoid):\n",
    "    \n",
    "    Z = W.dot(A_min) + B \n",
    "    A = act(Z)\n",
    "    \n",
    "    return Z, A\n",
    "\n",
    "\n",
    "def forwarding(model):\n",
    "\n",
    "    for i in range(1, n_layers):\n",
    "        \n",
    "        model['Z'][i], model['A'][i] = forward_1_layer(\n",
    "            W =     model['W'][i], \n",
    "            A_min = model['A'][i-1], \n",
    "            B =     model['B'][i], \n",
    "            act =   activations.sigmoid)\n",
    "     \n",
    "    model['loss'] = losses.binary_crossentropy(model['A'][final_layer_index], model['Y'])\n",
    "        \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "def backward_1_layer(W, A, dA, B, A_min, Z, learning_rate, actd=activations.dRelu):\n",
    "    \n",
    "    dZ = dA * Z\n",
    "    dA_min = np.dot(W.T, dZ)\n",
    "    dW = 1 / A_min.shape[1] * np.dot(dZ, A_min.T)\n",
    "    dB = 1 / A_min.shape[1] * np.dot(dZ, np.ones([dZ.shape[1], 1]))\n",
    "    \n",
    "    W = W - learning_rate * dW\n",
    "    B = B - learning_rate * dB\n",
    "\n",
    "    return dA_min, W, B\n",
    "\n",
    "\n",
    "def backwarding(model):\n",
    "\n",
    "    y_real = model['Y']\n",
    "    y_pred = model['A'][final_layer_index]\n",
    "    extra = 10e-5 #Against zero division\n",
    "    \n",
    "    model['dA'][final_layer_index] = (-y_real / (y_pred + extra)) - ((1-y_real)/(1-y_pred + extra))\n",
    "\n",
    "    for i in range(n_layers -1, 0, -1):\n",
    "\n",
    "        model['dA'][i-1], model['W'][i], model['B'][i] = backward_1_layer(\n",
    "            W = model['W'][i],\n",
    "            A = model['A'][i],\n",
    "            dA = model['dA'][i],\n",
    "            B = model['B'][i],\n",
    "            A_min = model['A'][i-1],\n",
    "            Z = model['Z'][i]\n",
    "            )\n",
    "        \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "model = initiate_model(x_train, y_train)\n",
    "\n",
    "n_layers = len(model['layers'])\n",
    "final_layer_index = n_layers - 1\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    model = forwarding(model)\n",
    "    \n",
    "    if (i%10==0):\n",
    "        print(model['loss']) \n",
    "        \n",
    "    model = backwarding(model)\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10.902031476184675\n",
      "10.855715105393058\n",
      "10.805409866230839\n",
      "10.750609079283542\n",
      "10.690685683080012\n",
      "10.624842167182992\n",
      "10.552028971633623\n",
      "10.470802873759936\n",
      "10.37906032106806\n",
      "10.273476244600486\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}